{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIS implementation from https://github.com/wmingwei/restricted-boltzmann-machine-deep-belief-network-deep-boltzmann-machine-in-pytorch/blob/fd21ac2461564252de01f99425ddabd5eec11f41/RBM/ais.py#L39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ais(rbm, step = 100, M = 100, seed = None):\n",
    "\n",
    "    W = rbm.W.data.numpy().T\n",
    "    v_bias = rbm.v_bias.data.numpy()\n",
    "    h_bias = rbm.h_bias.data.numpy()\n",
    "    \n",
    "    logZ0 = np.log((1+np.exp(v_bias))).sum() + np.log(1+np.exp(h_bias)).sum()\n",
    "    ratio = []\n",
    "    for i in range(M):\n",
    "        ratio.append(mcmc(step, seed = seed,  W = W, h_bias = h_bias, v_bias = v_bias))\n",
    "\n",
    "    ratio = np.array(ratio).reshape(len(ratio),1)\n",
    "    logZ = logZ0 + logmeanexp(ratio, axis = 0)\n",
    "\n",
    "    return logZ\n",
    "\n",
    "def mcmc(step, seed, W, h_bias, v_bias):\n",
    "\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    v = np.random.binomial(1, p=1/(1+np.exp(-v_bias))).reshape(1,-1)\n",
    "\n",
    "    logw = 0\n",
    "    for k in range(step):\n",
    "        logp_k = -free_energy(v, k*1.0/step*W, h_bias, v_bias)\n",
    "        logp_k1 = -free_energy(v, (k+1)*1.0/step*W, h_bias, v_bias)\n",
    "        logw += logp_k1 - logp_k\n",
    "\n",
    "        \n",
    "        p_h, h = v_to_h(v, (k+1)*1.0/step*W, h_bias)\n",
    "        p_v, v = h_to_v(h, (k+1)*1.0/step*W, v_bias)\n",
    "\n",
    "    return logw\n",
    "\n",
    "def free_energy(v, W, h_bias, v_bias):\n",
    "\n",
    "    Wv = np.clip(np.matmul(v,W) + h_bias,-80,80)\n",
    "    hidden = np.log(1+np.exp(Wv)).sum(1)\n",
    "    vbias = np.matmul(v, v_bias.T).reshape(hidden.shape)\n",
    "    return -hidden-vbias\n",
    "\n",
    "\n",
    "def logmeanexp(x, axis=None):\n",
    "    \n",
    "    x = np.asmatrix(x)\n",
    "    if not axis:\n",
    "        n = len(x)\n",
    "    else:\n",
    "        n = x.shape[axis]\n",
    "    \n",
    "    x_max = x.max(axis)\n",
    "    return (x_max + np.log(np.exp(x-x_max).sum(axis)) - np.log(n)).A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "n_vis = 10\n",
    "n_hidd = 20\n",
    "n_class = 30\n",
    "batch_size = 100\n",
    "\n",
    "input_data = np.random.rand(batch_size,n_vis)\n",
    "W = np.random.rand(n_vis,n_hidd)\n",
    "hidden_bias = np.random.rand(n_hidd)\n",
    "U = np.random.rand(n_class,n_hidd)\n",
    "\n",
    "tf.nn.sigmoid(tf.reshape((tf.repeat(tf.einsum(\"ni,ij->nj\",input_data,W)+hidden_bias,n_class)),shape = (batch_size,n_class,n_hidd))+U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
       "array([2.73073274, 2.9912447 , 3.71027033, 3.84297624, 2.84562585,\n",
       "       2.21961976, 3.12417395, 2.44894882, 2.60629273, 3.94587099,\n",
       "       3.91821798, 3.26617206, 2.06384555, 2.11889287, 2.81002009,\n",
       "       3.08849918, 2.47702441, 3.32047782, 3.2167166 , 1.92684327])>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_sum = tf.zeros([batch_size,self.n_hidden])\n",
    "class_weight_grad = tf.zeros([self.n_class,self.n_hidden])\n",
    "\n",
    "for i,c in enumerate(class_label):\n",
    "    positive_sum[i] += o_y_j[i, : , c]\n",
    "    class_weight_grad[c ,:] += positive_sum[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct LL(positive)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int64, numpy=array([0, 1, 2])>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Save_Load import from_dataset_to_array\n",
    "\n",
    "print(\"This may take some time\")\n",
    "CORRUPTED,CORRUPTED_LABEL = from_dataset_to_array(data_name = \"shot_noise\") \n",
    "DATA,DATA_LABEL = from_dataset_to_array(data_name = \"identity\")\n",
    "\n",
    "val_split = 1/3\n",
    "train_data,val_data = train_test_split(DATA, test_size = val_split,random_state = 42)\n",
    "train_corrupted,val_corrupted = train_test_split(CORRUPTED, test_size = val_split,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 11 # Time to train for each epoch approx 1 minute, and each model is repeated 10 times, thus, elapsed time will be [0.15,0.22]*epochs hours.\n",
    "             # For 100 epochs, maximum time limit should be 24 hours. \n",
    "             # Partitions(Walltime in hours)-> short(0.5), medium(6), large(120)\n",
    "\n",
    "lr = 0.01\n",
    "momentum = 0.5\n",
    "batch_size = 2**6\n",
    "SEED = 9\n",
    "\n",
    "n_hidden = 1000#81*5\n",
    "\n",
    "window = 1\n",
    "stride = 2\n",
    "\n",
    "windowList = []#[2,3,4]\n",
    "strideList = []#[4,4,4]\n",
    "\n",
    "\n",
    "dim = 28\n",
    "\n",
    "kwargs = vars_to_dict(batch_size = batch_size,n_visible = 28*28,n_hidden = n_hidden,\n",
    "                      window = window, stride = stride, windowList = windowList, strideList = strideList,\n",
    "                      epochs = EPOCHS,k_gibbs = 1,\n",
    "                      MAIN = MAIN,metrics = metrics,train_data=train_data,val_data=val_data,\n",
    "                      train_corrupted=train_corrupted,val_corrupted=val_corrupted,seed = SEED,\n",
    "                      lr = lr,momentum = momentum, dtype = dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Save_Load import save_rbm,load_rbm\n",
    "n_hid = 100 #1000,400,100\n",
    "rbm = RBM(**kwargs)\n",
    "aux = load_rbm(\"RBM_n_hidden_%s_method_LL_seed_9_epochs_100_lr_01_momentum_05_batch_size_64\"%n_hid,MAIN=MAIN)\n",
    "rbm.M = 2**9\n",
    "rbm.W = aux.W\n",
    "rbm.visible_bias = aux.visible_bias\n",
    "rbm.hidden_bias = aux.hidden_bias\n",
    "\n",
    "\n",
    "rbm.approx_log_Z = rbm.AIS_log_Z()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm.approx_log_Z\n",
    "rbm.approximated_LL(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neighbourhoods from covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Save_Load import from_dataset_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"This may take some time\")\n",
    "CORRUPTED,CORRUPTED_LABEL = from_dataset_to_array(data_name = \"shot_noise\") \n",
    "DATA,DATA_LABEL = from_dataset_to_array(data_name = \"identity\")\n",
    "\n",
    "val_split = 1/3\n",
    "train_data,val_data = train_test_split(DATA, test_size = val_split,random_state = 42)\n",
    "train_corrupted,val_corrupted = train_test_split(CORRUPTED, test_size = val_split,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.covariance import empirical_covariance\n",
    "cov = empirical_covariance(DATA[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 60000\n",
    "cov = np.cov(DATA[:m].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "fig = sn.heatmap(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_p_biggest(a,p):\n",
    "    #n = int(p*len(a))\n",
    "    #return a.argsort()[-n:][::-1]\n",
    "    m = np.max(a)\n",
    "    #print(a[a.argsort()[-3:][::-1]])\n",
    "    for i,ind in enumerate(a.argsort()[::-1]):\n",
    "        if a[ind]/m<p:\n",
    "            break\n",
    "    return a.argsort()[-i:][::-1]\n",
    "p = 0.25\n",
    "eps = 0.02\n",
    "mat = np.abs(cov)\n",
    "mat[np.where(mat<eps)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(mat)):\n",
    "    if np.any(mat[i,:]):\n",
    "        mat[i,return_p_biggest(mat[i,:],p)]=1\n",
    "        mat[i,i]=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "for i in range(len(mat)):\n",
    "    if np.any(mat[i,:]):\n",
    "        k+=1\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,7))\n",
    "fig = sn.heatmap(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = int(784/2)+5\n",
    "print(mat[ind,:])\n",
    "plt.imshow(mat[ind,:].reshape((28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.025\n",
    "plt.figure(figsize = (10,7))\n",
    "fig = sn.heatmap(np.abs(cov)>eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 28\n",
    "dim = 28\n",
    "figsize = kwargs.get(\"figsize\",(20,20))\n",
    "fig, axs = plt.subplots(n, n, figsize=figsize)\n",
    "\n",
    "eps = 0.001\n",
    "m = np.abs(cov)>eps #m = cov\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        axs[i,j].imshow(m[n*i+j].reshape((dim,dim)),cmap = plt.get_cmap('gray'))\n",
    "        axs[i,j].axis('off')\n",
    "plt.subplots_adjust(wspace=0, hspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.abs(cov[28*14+14,:].reshape((28,28))),cmap=\"gray\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
